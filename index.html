<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <title>Uniform Meaning Representation</title>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300%7CRoboto:300%7CSlabo+27px" rel="stylesheet">
    <link rel="stylesheet" href="law2020.css" type="text/css"/>
</head>

<body>

<div id="header">
  <table>
    <!--
    <tr valign="bottom"
      <td><img src="LAW14_Logo.svg" /></td>
      -->
    <tr>
      <td>

        <p class="title">Uniform Meaning Representation website</p>

      </td>
    </tr>

  </table>
</div>

<div id="subheader">
	<ul id="navigation">
		<li class="active"><a href="index.html">Home</a></li>
		<li><a href="people.html">People</a></li>
		<li><a href="publications.html">Publications</a></li>
		<li><a href="guidelines.html">UMR guidelines</a></li>
		<li><a href="tools.html">UMR tools</a></li>
		<li><a href="Participation.html">Participation</a></li>
	</ul>
</div>

  <table>

    <tr valign="top">

      <td>

        <div id="contents">
The goal of the  Uniform Meaning
Representation (UMR) project is to design  a meaning representation that can be used
to annotate the semantic content of a text. UMR
is primarily based on Abstract Meaning Representation
(AMR), an annotation framework initially designed for
English, but also draws from other meaning representations.
UMR extends AMR to other languages, particularly
morphologically complex, low-resource languages.
UMR also adds features to AMR that are critical
to semantic interpretation and enhances AMR by proposing a companion document-level representation
that captures linguistic phenomena such as coreference
as well as temporal and modal dependencies that potentially
go beyond sentence boundaries. UMR is intended to be
scalable, learnable, and cross-linguistically plausible. It is designed to support both lexical and logical inference.

        </div>

      <td class="sidebar">

        <div>
          <h3>Sponsors</h3>
        This project is supported by a grant from the IIS Di-
vision of National Science Foundation (Awards No. 1763926,

1764048, 1764091) entitled Building a Uniform Meaning Rep-
resentation for Natural Language Processing awarded to Nian-
wen Xue, James Pustejovsky, Martha Palmer and William Croft.
          <h3>News</h3>

            <p>
                <b>May 1, 2021</b>: UMR website is now up and running.
            </p>
          <!--
          <p><b>11 December 2020</b>: Added <a href="./virtual-conference-information.html">presentation information</a></p>

          <p><b>27 November 2020</b>: Added abstract for invited talk</p>
         -->

          <!-- example: <p><strong>February 2019</strong>: Submission is now open.</strong> -->


        </div>

      </td>
    </tr>
  </table>


<div id="footer">
  <div class="clearfix">
    <p>
      The 15th Linguistic Annotation and 3rd Meaning Representation Workshop (LAW-DMR 2021)
      &emsp;&emsp;&emsp;&emsp;
      Contact: <a href="mailto:law-dmr-2021-chairs@googlegroups.com">law-dmr-2021-chairs@googlegroups.com</a><br>

  </div>
</div>

</body>

</html>
